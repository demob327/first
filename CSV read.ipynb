{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '''\n",
    "0 0 Cambridge 110000\n",
    "4 -2 Boston 650000\n",
    "2 2 Somerville 80000\n",
    "0 -4 Brookline 60000\n",
    "-4 -2 Newton 90000\n",
    "-4 2 Waltham 60000\n",
    "1 4 Medford 60000\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n0 0 Cambridge 110000\\n4 -2 Boston 650000\\n2 2 Somerville 80000\\n0 -4 Brookline 60000\\n-4 -2 Newton 90000\\n-4 2 Waltham 60000\\n1 4 Medford 60000\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "place = namedtuple('place','Ian Lat name Pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '0 0 Cambridge 110000',\n",
       " '4 -2 Boston 650000',\n",
       " '2 2 Somerville 80000',\n",
       " '0 -4 Brookline 60000',\n",
       " '-4 -2 Newton 90000',\n",
       " '-4 2 Waltham 60000',\n",
       " '1 4 Medford 60000',\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-35aebedbba9e>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-35aebedbba9e>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    print('\\tParts:'),\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for line in data.split('\\n'):\n",
    "    print(\"Found on this line: [{contents}]\".format(contents=line)\n",
    "print('\\tParts:'),\n",
    "    for part in line.split(): # strip whitespace from ends, split on whitespace\n",
    "        print(\"[{part}]\").format(part=part),\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\administrateur\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from yellowbrick.datasets.loaders import load_occupancy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "X, y = load_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vega==1.3 in c:\\users\\administrateur\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vega==1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datapane'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-15754fae5947>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maltair\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdatapane\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://query1.finance.yahoo.com/v7/finance/download/GOOG?period2=1585222905&interval=1mo&events=history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datapane'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import datapane as dp\n",
    "\n",
    "df = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/GOOG?period2=1585222905&interval=1mo&events=history')\n",
    "\n",
    "chart = alt.Chart(df).encode(\n",
    "    x='Date:T',\n",
    "    y='Open'\n",
    ").mark_line().interactive()\n",
    "\n",
    "r = dp.Report(dp.Table(df), dp.Plot(chart))\n",
    "r.publish(name='stock_report', open=True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " jupyter nbextension install --sys-prefix --py vega\n",
    "\n",
    "# Optional in Jupyter Notebook: requires an up-to-date vega nbextension.\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL CODE\n",
    "def open_dataset(file_name):\n",
    "    \n",
    "    opened_file = open(file_name)\n",
    "    from csv import reader\n",
    "    read_file = reader(opened_file)\n",
    "    data = list(read_file)\n",
    "    \n",
    "    return data\n",
    "# SOLUTION CODE\n",
    "def open_dataset(file_name='AppleStore.csv'):\n",
    "    \n",
    "    opened_file = open(file_name)\n",
    "    from csv import reader\n",
    "    read_file = reader(opened_file)\n",
    "    data = list(read_file)\n",
    "    \n",
    "    return data\n",
    "\n",
    "apps_data = open_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ndarray = np.array([5, 10, 15, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ndarray = np.array([[5, 10, 15], \n",
    "                         [20, 25, 30]])\n",
    "print(data_ndarray.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's look at a comparison between working with ndarrays and list of lists to select one or more rows of data:\n",
    "\n",
    "Selecting rows from a 2D ndarray\n",
    "\n",
    "As shown above, we can select rows in ndarrays very similarly to lists of lists. In reality, what we're seeing is a kind of shortcut. For any 2D array, the full syntax for selecting data is:\n",
    "\n",
    "ndarray[row_index,column_index]\n",
    "​\n",
    "# or if you want to select all\n",
    "# columns for a given set of rows\n",
    "ndarray[row_index]\n",
    "Where row_index defines the location along the row axis and column_index defines the location along the column axis.\n",
    "\n",
    "Like lists, array slicing is from the first specified index up to — but not including — the second specified index. For example, to select the items at index 1, 2, and 3, we'd need to use the slice [1:4].\n",
    "\n",
    "This is how we select a single item from a 2D ndarray:\n",
    "\n",
    "Selecting a single item from a 2D ndarray\n",
    "\n",
    "With a list of lists, we use two separate pairs of square brackets back-to-back. With a NumPy ndarray, we use a single pair of brackets with comma-separated row and column locations.\n",
    "\n",
    "Let's practice selecting one row, multiple rows, and single items from our taxi ndarray.\n",
    "\n",
    "Instructions\n",
    "\n",
    "From the taxi ndarray:\n",
    "\n",
    "Select the row at index 0. Assign it to row_0.\n",
    "Select every column for the rows at indexes 391 to 500 inclusive. Assign them to rows_391_to_500.\n",
    "Select the item at row index 21 and column index 5. Assign it to row_21_column_5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import shutil as sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --no-deps '../input/weightedboxesfusion/' > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertTrainLabel():\n",
    "    df = pd.read_csv('../input/global-wheat-detection/train.csv')\n",
    "    bboxs = np.stack(df['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "    for i, column in enumerate(['x', 'y', 'w', 'h']):\n",
    "        df[column] = bboxs[:,i]\n",
    "    df.drop(columns=['bbox'], inplace=True)\n",
    "    df['x_center'] = df['x'] + df['w']/2\n",
    "    df['y_center'] = df['y'] + df['h']/2\n",
    "    df['classes'] = 0\n",
    "    from tqdm.auto import tqdm\n",
    "    import shutil as sh\n",
    "    df = df[['image_id','x', 'y', 'w', 'h','x_center','y_center','classes']]\n",
    "    \n",
    "    index = list(set(df.image_id))\n",
    "    \n",
    "    source = 'train'\n",
    "    if True:\n",
    "        for fold in [0]:\n",
    "            val_index = index[len(index)*fold//5:len(index)*(fold+1)//5]\n",
    "            for name,mini in tqdm(df.groupby('image_id')):\n",
    "                if name in val_index:\n",
    "                    path2save = 'val2017/'\n",
    "                else:\n",
    "                    path2save = 'train2017/'\n",
    "                if not os.path.exists('convertor/fold{}/labels/'.format(fold)+path2save):\n",
    "                    os.makedirs('convertor/fold{}/labels/'.format(fold)+path2save)\n",
    "                with open('convertor/fold{}/labels/'.format(fold)+path2save+name+\".txt\", 'w+') as f:\n",
    "                    row = mini[['classes','x_center','y_center','w','h']].astype(float).values\n",
    "                    row = row/1024\n",
    "                    row = row.astype(str)\n",
    "                    for j in range(len(row)):\n",
    "                        text = ' '.join(row[j])\n",
    "                        f.write(text)\n",
    "                        f.write(\"\\n\")\n",
    "                if not os.path.exists('convertor/fold{}/images/{}'.format(fold,path2save)):\n",
    "                    os.makedirs('convertor/fold{}/images/{}'.format(fold,path2save))\n",
    "                sh.copy(\"../input/global-wheat-detection/{}/{}.jpg\".format(source,name),'convertor/fold{}/images/{}/{}.jpg'.format(fold,path2save,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble_boxes import *\n",
    "def run_wbf(boxes, scores, image_size=1023, iou_thr=0.5, skip_box_thr=0.7, weights=None):\n",
    "    #boxes = [prediction[image_index]['boxes'].data.cpu().numpy()/(image_size-1) for prediction in predictions]\n",
    "    #scores = [prediction[image_index]['scores'].data.cpu().numpy() for prediction in predictions]\n",
    "    labels = [np.zeros(score.shape[0]) for score in scores]\n",
    "    boxes = [box/(image_size) for box in boxes]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    #boxes, scores, labels = nms(boxes, scores, labels, weights=[1,1,1,1,1], iou_thr=0.5)\n",
    "    boxes = boxes*(image_size)\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def TTAImage(image, index):\n",
    "    image1 = image.copy()\n",
    "    if index==0: \n",
    "        rotated_image = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image\n",
    "    elif index==1:\n",
    "        rotated_image2 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image2 = cv2.rotate(rotated_image2, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image2\n",
    "    elif index==2:\n",
    "        rotated_image3 = cv2.rotate(image1, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rotated_image3 = cv2.rotate(rotated_image3, cv2.ROTATE_90_CLOCKWISE)\n",
    "        return rotated_image3\n",
    "    elif index == 3:\n",
    "        return image1\n",
    "    \n",
    "def rotBoxes90(boxes, im_w, im_h):\n",
    "    ret_boxes =[]\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        x1, y1, x2, y2 = x1-im_w//2, im_h//2 - y1, x2-im_w//2, im_h//2 - y2\n",
    "        x1, y1, x2, y2 = y1, -x1, y2, -x2\n",
    "        x1, y1, x2, y2 = int(x1+im_w//2), int(im_h//2 - y1), int(x2+im_w//2), int(im_h//2 - y2)\n",
    "        x1a, y1a, x2a, y2a = min(x1, x2), min(y1, y2), max(x1, x2), max(y1, y2)\n",
    "        ret_boxes.append([x1a, y1a, x2a, y2a])\n",
    "    return np.array(ret_boxes)\n",
    "\n",
    "def detect1Image(im0, imgsz, model, device, conf_thres, iou_thres):\n",
    "    img = letterbox(im0, new_shape=imgsz)[0]\n",
    "    # Convert\n",
    "    img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x416x416\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "\n",
    "    img = torch.from_numpy(img).to(device)\n",
    "    img =  img.float()  # uint8 to fp16/32\n",
    "    img /= 255.0   \n",
    "    if img.ndimension() == 3:\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "    # Inference\n",
    "    pred = model(img, augment=False)[0]\n",
    "\n",
    "    # Apply NMS\n",
    "    pred = non_max_suppression(pred, conf_thres, iou_thres)\n",
    "\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for i, det in enumerate(pred):  # detections per image\n",
    "        # save_path = 'draw/' + image_id + '.jpg'\n",
    "        if det is not None and len(det):\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # Write results\n",
    "            for *xyxy, conf, cls in det:\n",
    "                boxes.append([int(xyxy[0]), int(xyxy[1]), int(xyxy[2]), int(xyxy[3])])\n",
    "                scores.append(conf)\n",
    "\n",
    "    return np.array(boxes), np.array(scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make pseudo labels for Yolov5\n",
    "from utils.datasets import *\n",
    "from utils.utils import *\n",
    "\n",
    "def makePseudolabel():\n",
    "    source = '../input/global-wheat-detection/test/'\n",
    "    weights = '../input/yolov5/bestv4.pt'\n",
    "    imgsz = 1024\n",
    "    conf_thres = 0.5\n",
    "    iou_thres = 0.6\n",
    "    is_TTA = True\n",
    "    \n",
    "    imagenames =  os.listdir(source)\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # Load model\n",
    "    model = torch.load(weights, map_location=device)['model'].float()  # load to FP32\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    dataset = LoadImages(source, img_size=imgsz)\n",
    "\n",
    "    path2save = 'train2017/'\n",
    "    if not os.path.exists('convertor/fold0/labels/'+path2save):\n",
    "        os.makedirs('convertor/fold0/labels/'+path2save)\n",
    "    if not os.path.exists('convertor/fold0/images/{}'.format(path2save)):\n",
    "        os.makedirs('convertor/fold0/images/{}'.format(path2save))\n",
    "            \n",
    "    for name in imagenames:\n",
    "        image_id = name.split('.')[0]\n",
    "        im01 = cv2.imread('%s/%s.jpg'%(source,image_id))  # BGR\n",
    "        if im01.shape[0]!=1024 or im01.shape[1]!=1024:\n",
    "            continue\n",
    "        assert im01 is not None, 'Image Not Found '\n",
    "        # Padded resize\n",
    "        im_w, im_h = im01.shape[:2]\n",
    "        if is_TTA:\n",
    "            enboxes = []\n",
    "            enscores = []\n",
    "            for i in range(4):\n",
    "                im0 = TTAImage(im01, i)\n",
    "                boxes, scores = detect1Image(im0, imgsz, model, device, conf_thres, iou_thres)\n",
    "                for _ in range(3-i):\n",
    "                    boxes = rotBoxes90(boxes, im_w, im_h)\n",
    "                    \n",
    "                enboxes.append(boxes)\n",
    "                enscores.append(scores) \n",
    "\n",
    "            boxes, scores, labels = run_wbf(enboxes, enscores, image_size = im_w, iou_thr=0.6, skip_box_thr=0.43)\n",
    "            boxes = boxes.astype(np.int32).clip(min=0, max=im_w)\n",
    "        else:\n",
    "            boxes, scores = detect1Image(im01, imgsz, model, device, conf_thres, iou_thres)\n",
    "\n",
    "        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "        \n",
    "        boxes = boxes[scores >= 0.05].astype(np.int32)\n",
    "        scores = scores[scores >=float(0.05)]\n",
    "        \n",
    "        lineo = ''\n",
    "        for box in boxes:\n",
    "            x1, y1, w, h = box\n",
    "            xc, yc, w, h = (x1+w/2)/1024, (y1+h/2)/1024, w/1024, h/1024\n",
    "            lineo += '0 %f %f %f %f\\n'%(xc, yc, w, h)\n",
    "            \n",
    "        fileo = open('convertor/fold0/labels/'+path2save+image_id+\".txt\", 'w+')\n",
    "        fileo.write(lineo)\n",
    "        fileo.close()\n",
    "        sh.copy(\"../input/global-wheat-detection/test/{}.jpg\".format(image_id),'convertor/fold0/images/{}/{}.jpg'.format(path2save,image_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
